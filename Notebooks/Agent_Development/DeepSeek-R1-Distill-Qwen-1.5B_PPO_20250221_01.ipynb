{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52958575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, AutoConfig\n",
    "from trl import PPOConfig#, PPOTrainer\n",
    "#import luxai_s3\n",
    "from luxai_s3.wrappers import LuxAIS3GymEnv, RecordEpisode\n",
    "#from luxai_s3.params import EnvParams\n",
    "import numpy as np\n",
    "from datasets import load_dataset, Dataset\n",
    "#from peft import LoraConfig, get_peft_model\n",
    "import os\n",
    "#from accelerate import infer_auto_device_map\n",
    "import gc\n",
    "#import copy\n",
    "gc.enable()\n",
    "\n",
    "#from stable_baselines3 import PPO\n",
    "#import gymnasium as gym\n",
    "#import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcf8610",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "os.environ[\"FLASH_ATTENTION\"] = \"1\"\n",
    "torch._dynamo.config.capture_scalar_outputs = True\n",
    "torch._dynamo.config.cache_size_limit = 64\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "np.set_printoptions(linewidth=200)\n",
    "# Configure CUDA memory management\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128,garbage_collection_threshold:0.8\"\n",
    "torch.cuda.empty_cache()\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Enable gradient checkpointing\n",
    "os.environ[\"PYTORCH_ATTENTION_USE_MEMORY_EFFICIENT_ATTENTION\"] = \"1\"\n",
    "os.environ[\"TORCH_USE_CUDA_DSA\"] = \"1\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8d0115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prep dataset\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "Respond in the following format:\n",
    "<reasoning>\n",
    "...\n",
    "</reasoning>\n",
    "<answer>\n",
    "...\n",
    "</answer>\n",
    "\"\"\"\n",
    "\n",
    "XML_COT_FORMAT = \"\"\"\\\n",
    "<reasoning>\n",
    "{reasoning}\n",
    "</reasoning>\n",
    "<answer>\n",
    "{answer}\n",
    "</answer>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f17ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_xml_answer(text: str) -> str:\n",
    "    answer = text.split(\"<answer>\")[-1]\n",
    "    answer = answer.split(\"</answer>\")[0]\n",
    "    return answer.strip()\n",
    "\n",
    "def extract_hash_answer(text: str) -> str | None:\n",
    "    if \"####\" not in text:\n",
    "        return None\n",
    "    return text.split(\"####\")[1].strip()\n",
    "\n",
    "# uncomment middle messages for 1-shot prompting\n",
    "def get_gsm8k_questions(split = \"train\") -> Dataset:\n",
    "    data = load_dataset('openai/gsm8k', 'main')[split] # type: ignore\n",
    "    data = data.map(lambda x: { # type: ignore\n",
    "        'prompt': [\n",
    "            {'role': 'system', 'content': SYSTEM_PROMPT},\n",
    "            {'role': 'user', 'content': x['question']}\n",
    "        ],\n",
    "        'answer': extract_hash_answer(x['answer'])\n",
    "    }) # type: ignore\n",
    "    return data # type: ignore\n",
    "\n",
    "#dataset = get_gsm8k_questions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe737742",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "\n",
    "# ✅ Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# ✅ Ensure pad token is set correctly\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# ✅ Optimized quantization configuration\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,  # ✅ Add nested quantization for better memory usage\n",
    "    bnb_4bit_quant_storage=\"bfloat16\"  # Enable quantized storage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa439ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_length = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaa520d",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_autoconfig = AutoConfig.from_pretrained(model_name)\n",
    "policy_autoconfig.max_position_embeddings = 11000 + response_length\n",
    "policy_autoconfig.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70bbfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        trust_remote_code=True,\n",
    "        device_map=\"auto\",\n",
    "        quantization_config=bnb_config,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        config=policy_autoconfig,\n",
    "        attn_implementation=\"flash_attention_2\",\n",
    "        # low_cpu_mem_usage=True\n",
    "    )\n",
    "\n",
    "    # model.gradient_checkpointing_enable()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad949a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reward functions\n",
    "def strict_format_reward_func(completion) -> float:\n",
    "    \"\"\"Reward function that checks if the completion has a specific format.\"\"\"\n",
    "    pattern = r\"^<answer>\\n.*?\\n</answer>\\n$\"\n",
    "    match = re.match(pattern, completion)\n",
    "\n",
    "    return 0.5 * 100 if match else 0.0\n",
    "\n",
    "def soft_format_reward_func(completion) -> float:\n",
    "    \"\"\"Reward function that checks if the completion has a specific format.\"\"\"\n",
    "    pattern = r\"<answer>.*?</answer>\"\n",
    "    match = re.match(pattern, completion)\n",
    "\n",
    "    return 0.5 * 100 if match else 0.0\n",
    "\n",
    "def count_xml(text) -> float:\n",
    "    count = 0.0\n",
    "    if text.count(\"\\n<answer>\\n\") == 1:\n",
    "        count += 0.125\n",
    "        count -= len(text.split(\"\\n</answer>\\n\")[-1])*0.001\n",
    "    if text.count(\"\\n</answer>\") == 1:\n",
    "        count += 0.125\n",
    "        count -= (len(text.split(\"\\n</answer>\")[-1]) - 1)*0.001\n",
    "\n",
    "    return count\n",
    "\n",
    "def xmlcount_reward_func(completion) -> float:\n",
    "\n",
    "    return count_xml(completion) * 100\n",
    "\n",
    "def answer_format_reward_func(completion, sap_range) -> float:\n",
    "    # extract_xml_answer should extract the text between the <answer> tags.\n",
    "    answer = extract_xml_answer(completion)\n",
    "    \n",
    "    # Updated regex pattern: for non-sap actions, force \"0, 0\" after the digit.\n",
    "    answer_pattern = re.compile(\n",
    "        r\"^Unit\\s+([0-9]+):\\s+((?:[0-4],\\s*0,\\s*0)|(?:5,\\s*-?\\d+,\\s*-?\\d+))$\"\n",
    "    )\n",
    "\n",
    "    answer_score = 0.0\n",
    "    # Split the answer into lines and remove any extra whitespace.\n",
    "    lines = [line.strip() for line in answer.strip().split(\"\\n\") if line.strip()]\n",
    "    \n",
    "    # Penalize if we do not have exactly 16 lines (one per unit)\n",
    "    if len(lines) != 16:\n",
    "        answer_score -= 0.2  # adjust penalty as desired\n",
    "\n",
    "    for line in lines:\n",
    "        match = answer_pattern.match(line)\n",
    "        if match:\n",
    "            # Reward for a valid line\n",
    "            answer_score += 0.5 / 16\n",
    "            unit_number = int(match.group(1))\n",
    "            # Check that unit number is in the valid range\n",
    "            if unit_number < 0 or unit_number > 15:\n",
    "                answer_score -= 0.1 / 16\n",
    "            else:\n",
    "                answer_score += 0.2 / 16\n",
    "\n",
    "            unit_action_str = match.group(2)\n",
    "            # Since our pattern now always expects three parts separated by commas:\n",
    "            parts = [part.strip() for part in unit_action_str.split(',')]\n",
    "            if len(parts) != 3:\n",
    "                answer_score -= 0.1 / 16\n",
    "                continue\n",
    "            try:\n",
    "                action_num = int(parts[0])\n",
    "                dx = int(parts[1])\n",
    "                dy = int(parts[2])\n",
    "            except:\n",
    "                answer_score -= 0.1 / 16\n",
    "                continue\n",
    "\n",
    "            # For sap action (5), check that the provided (dx, dy) are within the allowed range.\n",
    "            if action_num == 5:\n",
    "                answer_score += 0.2 / 16  # reward for correct action code\n",
    "                sap_action_range = max(abs(dx), abs(dy))  # or use Euclidean distance if desired\n",
    "                if sap_action_range > sap_range:\n",
    "                    answer_score -= 0.1 / 16\n",
    "                else:\n",
    "                    answer_score += 0.2 / 16\n",
    "            else:\n",
    "                # For non-sap actions (0-4), dx and dy must be exactly 0.\n",
    "                if dx != 0 or dy != 0:\n",
    "                    answer_score -= 0.1 / 16\n",
    "                else:\n",
    "                    answer_score += 0.2 / 16\n",
    "                # Also, ensure action_num is within [0,4].\n",
    "                if action_num < 0 or action_num > 4:\n",
    "                    answer_score -= 0.1 / 16\n",
    "                else:\n",
    "                    answer_score += 0.2 / 16\n",
    "        else:\n",
    "            # Penalize for any line that doesn't match the required format.\n",
    "            answer_score -= 0.1\n",
    "\n",
    "    return answer_score * 100\n",
    "\n",
    "\n",
    "def point_gain_reward_func(reward_score) -> float:\n",
    "\n",
    "    return reward_score if reward_score > 0.0 else -1\n",
    "\n",
    "def match_won_reward_func(match_won) -> float:\n",
    "\n",
    "    return 300.0 if match_won else 0.0\n",
    "\n",
    "def match_lost_reward_func(match_lost) -> float:\n",
    "\n",
    "    return -300.0 if match_lost else 0.0\n",
    "\n",
    "def game_won_reward_func(game_won) -> float:\n",
    "\n",
    "    return 1000.0 if game_won else 0.0\n",
    "\n",
    "def game_lost_reward_func(game_lost) -> float:\n",
    "\n",
    "    return -500.0 if game_lost else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d01ec0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_games_to_train = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27b664b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir=\"outputs/DeepSeek-R1-Distill-Qwen-1.5B-PPO\"\n",
    "run_name=\"DeepSeek-R1-Distill-Qwen-1.5B-PPO-20250221_01\"\n",
    "\n",
    "training_args = PPOConfig(\n",
    "    output_dir=output_dir,\n",
    "    run_name=run_name,\n",
    "    batch_size=1,\n",
    "    learning_rate=5e-6,\n",
    "    adam_beta1=0.9,\n",
    "    adam_beta2=0.99,\n",
    "    weight_decay=0.1,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    logging_steps=1,\n",
    "    bf16=True,\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_sample_generations=0,\n",
    "    max_grad_norm=0.1,\n",
    "    num_train_epochs=1,\n",
    "    save_steps=50,\n",
    "    log_on_each_node=False,\n",
    "    report_to=\"none\",\n",
    "    num_ppo_epochs=1,\n",
    "    cliprange=0.2,\n",
    "    vf_coef=1.0,\n",
    "    kl_coef=0.01,\n",
    "    prediction_loss_only=True,\n",
    "    gradient_checkpointing=True,\n",
    "    optim=\"adamw_torch_fused\",\n",
    "    max_steps=1,\n",
    "    per_device_train_batch_size=1,\n",
    "    torch_empty_cache_steps=1,\n",
    "    total_episodes=num_games_to_train,\n",
    "    micro_batch_size=1,\n",
    "    mini_batch_size=1,\n",
    "    local_batch_size=1,\n",
    "    response_length=response_length,\n",
    "    temperature=0.6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3394f083",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args.num_mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e75ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args.mini_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4eb99a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_model_1 = create_model()\n",
    "temp_model_2 = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff44f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_model_1.config.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08cfd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4878fc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SharedPolicyAndValueModel(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.base = model\n",
    "        # Value head: a lightweight linear layer that maps hidden_size to a scalar.\n",
    "        self.value_head = nn.Linear(model.config.hidden_size, 1).to(model.device, dtype=torch.bfloat16)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, **kwargs):\n",
    "        # Forward pass through the shared transformer backbone.\n",
    "        outputs = self.base.model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_hidden_states=True,  # we need hidden states for value prediction\n",
    "            **kwargs\n",
    "        )\n",
    "        hidden_states = outputs.hidden_states[-1]  # final layer: (batch, seq_len, hidden_size)\n",
    "        # Policy logits: project hidden states to vocabulary size.\n",
    "        logits = self.base.lm_head(hidden_states)\n",
    "        # Value: Use a simple pooling strategy.\n",
    "        # For example, use the hidden state corresponding to the first token (or [CLS]) as a summary.\n",
    "        value = self.value_head(hidden_states)\n",
    "        value = value.squeeze(-1)\n",
    "        # Alternatively, you can average the hidden states across the sequence:\n",
    "        # pooled = hidden_states.mean(dim=1)\n",
    "        # value = self.value_head(pooled)\n",
    "        return logits, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c10e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = SharedPolicyAndValueModel(temp_model_1)\n",
    "model_2 = SharedPolicyAndValueModel(temp_model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaa4232",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3742d95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = RecordEpisode(\n",
    "    LuxAIS3GymEnv(numpy_output=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dddc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Modified_PPO_Trainer.ppo_trainer_20250221_01 import ModifiedPPOTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688d06ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = ModifiedPPOTrainer(\n",
    "    model_1=model_1,\n",
    "    model_2=model_2,\n",
    "    processing_class=tokenizer,\n",
    "    args=training_args,\n",
    "    reward_functions=[\n",
    "        strict_format_reward_func,\n",
    "        soft_format_reward_func,\n",
    "        xmlcount_reward_func,\n",
    "        answer_format_reward_func,\n",
    "        point_gain_reward_func,\n",
    "        match_won_reward_func,\n",
    "        match_lost_reward_func,\n",
    "        game_won_reward_func,\n",
    "        game_lost_reward_func\n",
    "    ],\n",
    "    game_env=env,\n",
    "    num_games_to_train=num_games_to_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16fb0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3da037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba321a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a6a0db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372ecbc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eefc4d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c651989d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 10395677,
     "sourceId": 86411,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 143.048125,
   "end_time": "2024-12-26T20:02:43.573801",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-26T20:00:20.525676",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
