{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e587d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U luxai-s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52958575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, AutoConfig\n",
    "from trl import PPOTrainer, PPOConfig\n",
    "import luxai_s3\n",
    "from luxai_s3.wrappers import LuxAIS3GymEnv, RecordEpisode\n",
    "from luxai_s3.params import EnvParams\n",
    "import numpy as np\n",
    "from datasets import load_dataset, Dataset\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import os\n",
    "from accelerate import infer_auto_device_map\n",
    "import gc\n",
    "gc.enable()\n",
    "import copy\n",
    "\n",
    "#from stable_baselines3 import PPO\n",
    "#import gymnasium as gym\n",
    "#import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcf8610",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "os.environ[\"FLASH_ATTENTION\"] = \"1\"\n",
    "torch._dynamo.config.capture_scalar_outputs = True\n",
    "torch._dynamo.config.cache_size_limit = 64\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "np.set_printoptions(linewidth=200)\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128,garbage_collection_threshold:0.8\"\n",
    "torch.cuda.empty_cache()\n",
    "torch.backends.cudnn.benchmark = False\n",
    "os.environ[\"PYTORCH_ATTENTION_USE_MEMORY_EFFICIENT_ATTENTION\"] = \"1\"\n",
    "os.environ[\"TORCH_USE_CUDA_DSA\"] = \"1\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c971a92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset('openai/gsm8k', 'main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97761178",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data['train']\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc0e296",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f68f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd15183",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8d0115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prep dataset\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "Respond in the following format:\n",
    "<reasoning>\n",
    "...\n",
    "</reasoning>\n",
    "<answer>\n",
    "...\n",
    "</answer>\n",
    "\"\"\"\n",
    "\n",
    "XML_COT_FORMAT = \"\"\"\\\n",
    "<reasoning>\n",
    "{reasoning}\n",
    "</reasoning>\n",
    "<answer>\n",
    "{answer}\n",
    "</answer>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f17ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_xml_answer(text: str) -> str:\n",
    "    answer = text.split(\"<answer>\")[-1]\n",
    "    answer = answer.split(\"</answer>\")[0]\n",
    "    return answer.strip()\n",
    "\n",
    "def extract_hash_answer(text: str) -> str | None:\n",
    "    if \"####\" not in text:\n",
    "        return None\n",
    "    return text.split(\"####\")[1].strip()\n",
    "\n",
    "# uncomment middle messages for 1-shot prompting\n",
    "def get_gsm8k_questions(split = \"train\") -> Dataset:\n",
    "    data = load_dataset('openai/gsm8k', 'main')[split] # type: ignore\n",
    "    data = data.map(lambda x: { # type: ignore\n",
    "        'prompt': [\n",
    "            {'role': 'system', 'content': SYSTEM_PROMPT},\n",
    "            {'role': 'user', 'content': x['question']}\n",
    "        ],\n",
    "        'answer': extract_hash_answer(x['answer'])\n",
    "    }) # type: ignore\n",
    "    return data # type: ignore\n",
    "\n",
    "dataset = get_gsm8k_questions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe737742",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "\n",
    "# ✅ Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# ✅ Ensure pad token is set correctly\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# ✅ Optimized quantization configuration\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,  # ✅ Add nested quantization for better memory usage\n",
    "    bnb_4bit_quant_storage=\"bfloat16\"  # Enable quantized storage\n",
    ")\n",
    "\n",
    "autoconfig = AutoConfig.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaa520d",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoconfig.max_position_embeddings = 10000\n",
    "autoconfig.use_cache = False\n",
    "autoconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec2f3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from lux.utils import direction_to\n",
    "#import sys\n",
    "import numpy as np\n",
    "\n",
    "answer_format = {'content': '\\nRespond in the following format:\\n<reasoning>\\n...\\n</reasoning>\\n<answer>\\n...\\n</answer>\\n', 'role': 'system'}\n",
    "\n",
    "game_rules = {'content': \n",
    "\"\"\"\n",
    "!!!GAME RULES!!!\n",
    "Environment\n",
    "Two teams compete against each other on a 2D map in a best of 5 match sequence (called a game) with each match lasting 100 time steps. Both teams have a pool of units they can control to gain points around the map while also trying to prevent the other team from doing the same.\n",
    "A core objective of this game is a balanced strategy of exploration and exploitation. It is recommended to explore more in the first match or two before leveraging gained knowledge about the map and opponent behavior to win the latter matches.\n",
    "Map\n",
    "The map is a randomly generated 2D grid of size 24x24. There are several core features that make up the map: Unknown Tiles, Empty Tiles, Asteroid Tiles, Nebula Tiles, Energy Tiles, Relic Nodes, and Relic Fragments. Notably, in a game, the map is never regenerated completely between matches. Whatever is the state of the map at the end of one match is what is used for the next match.\n",
    "Unknown Tiles\n",
    "These are tiles that are not visible. They can be any type of tile but are not visible to you until a unit is within sensor range of that tile.\n",
    "Empty Tiles\n",
    "These are empty tiles in space without anything special about them. Units and tiles can be placed/move onto these tiles.\n",
    "Asteroid Tiles\n",
    "Asteroid tiles are impassable tiles that block anything from moving/spawning onto them. These tiles might move around over time during the map in a symmetric fashion. Sometimes asteroid tiles might move on top of existing units. In the game the unit is not removed as a result of this and can still take actions and move around provided there is an non asteroid tile adjacent to it.\n",
    "Nebula Tiles\n",
    "Nebula tiles are passable tiles with a number of features. These tiles might move around over time during the map in a symmetric fashion.\n",
    "Vision Reduction: Nebula tiles can reduce/block vision of units. Because of vision reduction it is even possible for a unit to be unable to see itself while still being able to move! See Vision section below for more details on how team vision is determined. All nebula tiles have the same vision reduction value called params.nebula_tile_vision_reduction which is randomized from 0 to 3.\n",
    "Energy Reduction: Nebula tiles can reduce the energy of units that end their turn on them. All nebula tiles have the same energy reduction value called params.nebula_tile_energy_reduction.\n",
    "In Map Tile Types, empty tiles are represented by 0, asteroid tiles by 1, nebula tiles by 2, and unknown tiles by -1.\n",
    "Energy Tiles\n",
    "Energy tiles are mysterious objects that emit energy fields which can be harvested by units. These tiles might move around over time during the map in a symmetric fashion. In code, what actually occurs in each game is energy tiles are randomly generated on the map symmetrically and a random function is generated for each tile. Each energy tile's function is a function of distance. The energy value of a tile on a map is determined to be the sum of the energy tile functions applied to the distance between tile and each tile.\n",
    "Relic Nodes\n",
    "Relic nodes are objects in space that enable ships to go near it to gain team points. These relic nodes however are ancient and thus fragmented. As a result, only certain tiles near the relic nodes when a friendly ship is on it will gain points. The tiles that yield points are always hidden and can only be discovered by trial and error by moving around the relic nodes. Relic node positions themselves can be observed if withins sensor range. The tiles around relic nodes can overlap with tiles of other relic nodes but will not yield extra points if that occurs and is treated as one tile.\n",
    "In code, a random 5x5 configuration / mask centered on the relic node is generated indicating which tiles yield points and which don't. Multiple ships can stack on one tile but will only yield at most one point per tile. Note that ship stacking can be risky due to the sapping action.\n",
    "Units\n",
    "Units in the game are ships that can move one tile in 5 directions (center, up, right, down, left) and perform a ranged energy sapping action. Units can overlap with other friendly units if they move onto the same tile. Units have a energy property which determines whether they can perform actions and start with 100 energy and can have a max of 400 energy. Energy is recharged via the energy field of the map. They always spawn on one of the two corners of the map depending on which team they are on.\n",
    "Note that nebula tiles and energy fields can modify the energy of a unit when it is on that tile. However they can never reduce the energy of a unit below 0, only opposing units can do that which will then remove the unit from the game to be respawned at a later timestep. Unit IDs range from 0 to params.max_units - 1 for each team, and are recycled when units are spawned in if a previous one was removed.\n",
    "Move Actions\n",
    "All move actions except moving center cost params.unit_move_cost energy to perform. Moving center is always free (a zero action). Attempting to move off the edge of the map results in no movement occuring but energy is still consumed. Units cannot move onto tiles with an impassible feature like an asteroid tile.\n",
    "Sap Actions\n",
    "The sap action lets a unit target a specific tile on the map within a range called params.unit_sap_range and reduces the energy of each opposition unit on the target tile by params.unit_sap_cost while also costing unit_sap_cost energy to use. Moreover, any opposition units on the 8 adjacent tiles to the target tile are also sapped and their energy is reduced by params.unit_sap_cost * params.unit_sap_dropoff_factor.\n",
    "Sap actions are submitted to the game engine / environment as a delta x and delta y value relative to the unit's current position. The delta x and delta y value magnitudes must both be <= params.unit_sap_range, so the sap range is a square around the unit.\n",
    "Generally sap actions are risky since a single miss means your ships lose energy while the opponent does not. The area of effect can mitigate this risk somewhat depending on game parameters. Sap actions can however prove very valuable when opposition ships are heavily stacked and get hit as sapping the stacked tile hits every ship on the tile.\n",
    "Vision\n",
    "A team's vision is the combined vision of all units on that team. Team vision is essentially a boolean mask / matrix over the 2D map indicating whether that tile's information is visible to the team. In this game, you can think of each unit having an \"eye in the sky\" sattelite that is capturing information about the units surroundings, but this sattelite has reduced accuracy the farther away the tile is from the unit.\n",
    "To determine which map tiles are visible to a team, we compute a vision power value for each tile on the map. For each unit on a team, we check each tile within the unit's sensor range and add 1 + params.unit_sensor_range - min(dx, dy) to the vision power map at tile (x+dx, y+dy) where (x,y) is the unit's position and (dx, dy) is the offset from the unit's position and abs(dx) <= params.unit_sensor_range and abs(dy) <= params.unit_sensor_range.\n",
    "Nebula tiles have a vision reduction value of params.nebula_tile_vision_reduction. This number is reduced from every tile's vision power if that tile is a nebula tile.\n",
    "When a unit is near a nebula tile, it can't see details about some nebula tiles, but it can see tiles beyond nebula tiles.\n",
    "When a unit is inside a nebula tile, if the nebula vision reduction is powerful enough, the unit cannot even see itself or any other nebula tiles.\n",
    "Unit vision can overlap and increase the vision power linearly, which can help handle the situations like above when you cannot see anything.\n",
    "Collisions / Energy Void Fields\n",
    "In close quarters, units can impact each other in two ways, via direct collisions or by being adjacent to each other and sapping energy via their energy void fields.\n",
    "In the event of two or more units from opposing teams occupy the same tile at the end of a turn, the team with the highest aggregate energy among its units on that tile survive, while the units of the opposing teams are removed from the game. If it is a tie, all units are removed from the game.\n",
    "Furthermore, each unit generates an \"energy void\" field around itself that affects all cardinally (up, right, down left) adjacent opposition units. To determine how exactly each unit is affected by these energy void fields, we compute a 2D map for each team indicating the energy void strength at each tile. A unit contributes to tiles adjacent to itself a energy void strength equal to the total amount of energy the unit has at the start of the turn multiplied by params.unit_energy_void_factor rounded down. After a energy void map is computed for each team, a unit's energy is reduced by the energy void strength of the tile it is on divided by the total number of units on that tile. Note that units removed due to collisions do not contribute to the energy void field.\n",
    "The energy void fields generally encourage stacking units to better spread out energy sapped by energy void fields of opposition units.\n",
    "Win Conditions\n",
    "To win the game, the team must have won the most matches out of the 5 match sequence.\n",
    "To win a match, the team must have gained more relic points than the other team at the end of the match. If the relic points scores are tied, then the match winner is decided by who has more total unit energy. If that is also tied then the winner is chosen at random.\n",
    "Match Resolution Order\n",
    "At each time step of a match, we run the following steps in order:\n",
    "1. Move all units that have enough energy to move\n",
    "2. Execute the sap actions of all units that have enough energy to do so\n",
    "3. Resolve collisions and apply energy void fields\n",
    "4. Update the energy of all units based on their position (energy fields and nebula tiles)\n",
    "5. Spawn units for all teams. Remove units that have less than 0 energy.\n",
    "6. Determine the team vision / sensor masks for all teams and mask out observations accordingly\n",
    "7. Environment objects like asteroids/nebula tiles/energy tiles move around in space\n",
    "8. Compute new team points\n",
    "Note that each match runs for params.max_steps_in_match steps and you take that many actions that affect the game. However, you will actually receive params.max_steps_in_match + 1 frames of observations since the very first frame will either be empty or the previous match's final observation (actions on these observations will not do anything).\n",
    "Game Parameters\n",
    "The full set of game parameters can be found here in the codebase.\n",
    "Randomized Game Parameters / Map Generation\n",
    "There are a number of randomized game paramteres which can modify and even disable/enable certain game mechanics. None of these game parameters are changed between matches in a game. The majority of these parameters are also not given to the teams themselves and must be discovered through exploration.\n",
    "env_params_ranges = dict(\n",
    "    map_type=[1],\n",
    "    unit_move_cost=list(range(1, 6)), # list(range(x, y)) = [x, x+1, x+2, ... , y-1]\n",
    "    unit_sensor_range=list(range(2, 5)),\n",
    "    nebula_tile_vision_reduction=list(range(0,4)),\n",
    "    nebula_tile_energy_reduction=[0, 0, 10, 25],\n",
    "    unit_sap_cost=list(range(30, 51)),\n",
    "    unit_sap_range=list(range(3, 8)),\n",
    "    unit_sap_dropoff_factor=[0.25, 0.5, 1],\n",
    "    unit_energy_void_factor=[0.0625, 0.125, 0.25, 0.375],\n",
    "    # map randomizations\n",
    "    nebula_tile_drift_speed=[-0.05, -0.025, 0.025, 0.05],\n",
    "    energy_tile_drift_speed=[0.01, 0.02, 0.03, 0.04, 0.05],\n",
    "    energy_tile_drift_magnitude=list(range(3, 6))\n",
    ")\n",
    "These parameter ranges (and other parameters) are subject to change in the beta phase of this competition as we gather feedback and data.\n",
    "There are 6 actions that can be taken by a unit in this game: 0 = center, 1 = up, 2 = right, 3 = down, 4 = left, 5 = sap.\n",
    "So your answer should be in this format:\n",
    "Unit 0: action(from 0 to 5)\n",
    "Unit 1: action(from 0 to 5)\n",
    "Unit 2: action(from 0 to 5)\n",
    "Unit 3: action(from 0 to 5)\n",
    "Unit 4: action(from 0 to 5)\n",
    "Unit 5: action(from 0 to 5)\n",
    "Unit 6: action(from 0 to 5)\n",
    "Unit 7: action(from 0 to 5)\n",
    "Unit 8: action(from 0 to 5)\n",
    "Unit 9: action(from 0 to 5)\n",
    "Unit 10: action(from 0 to 5)\n",
    "Unit 11: action(from 0 to 5)\n",
    "Unit 12: action(from 0 to 5)\n",
    "Unit 13: action(from 0 to 5)\n",
    "Unit 14: action(from 0 to 5)\n",
    "Unit 15: action(from 0 to 5)\n",
    "However, if you choose to sap(5), you should also provide the direction of the sap, which is a pair of integers (dx, dy) where dx and dy are the relative coordinates of the target tile from the unit's current position. The magnitudes of dx and dy must be less than or equal to the unit's sap range. For example, if unit 3 is at (5, 5) and you want to sap the tile at (7, 7), your answer for unit 3 should be 5, 2, 2.\n",
    "Also, you can only take actions for the units that are available to you in the current timestep. If you take an action for a unit that is not available to you, the game engine will ignore that action.\n",
    "Additionally, you can only take one action per unit per timestep. If you take multiple actions for a single unit in a timestep, the game engine will ignore all but the first action.\n",
    "So, below is an example of a valid answer:\n",
    "Unit 0: 1\n",
    "Unit 1: 2\n",
    "Unit 2: 5, 2, 2\n",
    "Unit 3: 0\n",
    "Unit 4: 5, 1, 1\n",
    "Unit 5: 5, -1, -2\n",
    "Unit 6: 5, -2, 2\n",
    "Unit 7: 5, 0, 0\n",
    "Unit 8: 4\n",
    "Unit 9: 0\n",
    "Unit 10: 3\n",
    "Unit 11: 2\n",
    "Unit 12: 1\n",
    "Unit 13: 0\n",
    "Unit 14: 5, -4, 5\n",
    "Unit 15: 5, 3, -3\n",
    "In the above example, unit 0 moves up, unit 1 moves right, unit 2 saps at (2, 2) relative to its current position, unit 3 does nothing, unit 4 saps at (1, 1) relative to its current position, unit 5 saps at (-1, -2) relative to its current position, unit 6 saps at (-2, 2) relative to its current position, unit 7 saps at (0, 0) relative to its current position, unit 8 moves left, unit 9 does nothing, unit 10 moves down, unit 11 moves right, unit 12 moves up, unit 13 does nothing, unit 14 saps at (-4, 5) relative to its current position, and unit 15 saps at (3, -3) relative to its current position.\n",
    "\"\"\"\n",
    ", 'role': 'system'\n",
    "}\n",
    "\n",
    "\n",
    "# Helper functions\n",
    "def manhattan_distance(pos1, pos2):\n",
    "    return abs(pos1[0] - pos2[0]) + abs(pos1[1] - pos2[1])\n",
    "\n",
    "def absolute_distance(pos1, pos2):\n",
    "    return max(abs(pos1[0] - pos2[0]), abs(pos1[1] - pos2[1]))\n",
    "\n",
    "def find_opposite_corner_coords(array, row, col):\n",
    "    \"\"\"\n",
    "    Given a 2D array and a coordinate (row, col), this function returns the opposite corner coordinates.\n",
    "\n",
    "    :param array: 2D list or NumPy array\n",
    "    :param row: Row index of the given point\n",
    "    :param col: Column index of the given point\n",
    "    :return: (row', col') - Opposite corner coordinates\n",
    "    \"\"\"\n",
    "    num_rows = len(array)\n",
    "    num_cols = len(array[0]) if num_rows > 0 else 0\n",
    "\n",
    "    # Opposite coordinates\n",
    "    opp_row = num_rows - 1 - row\n",
    "    opp_col = num_cols - 1 - col\n",
    "\n",
    "    return (opp_row, opp_col)\n",
    "\n",
    "\n",
    "class Agent():\n",
    "    def __init__(self, player: str, env_cfg) -> None:\n",
    "        self.player = player\n",
    "        self.enemy_player = \"player_1\" if self.player == \"player_0\" else \"player_0\"\n",
    "        self.team_id = 0 if self.player == \"player_0\" else 1\n",
    "        self.enemy_team_id = 1 if self.team_id == 0 else 0\n",
    "        #np.random.seed(0)\n",
    "        self.env_cfg = env_cfg\n",
    "        #self.min_unit_sap_dropoff_factor = 1\n",
    "        #self.min_sap_power = self.unit_sap_cost * self.min_unit_sap_dropoff_factor\n",
    "        self.map_height = env_cfg[\"map_height\"]\n",
    "        self.map_width = env_cfg[\"map_width\"]\n",
    "        self.my_spawn_location = None\n",
    "        self.enemy_spawn_location = None\n",
    "        self.first_spawn = False\n",
    "        self.llm_input = None\n",
    "\n",
    "        self.map_explored_status = np.zeros((self.map_height, self.map_width), dtype=int)\n",
    "\n",
    "        \n",
    "\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            trust_remote_code=True,\n",
    "            device_map=\"auto\",  # Let Accelerate handle device placement\n",
    "            #device_map={\"0\": \"14GiB\", \"cpu\": \"64GiB\"},  # Let Accelerate handle device placement\n",
    "            quantization_config=bnb_config,\n",
    "            torch_dtype=torch.bfloat16,\n",
    "            config=autoconfig,\n",
    "            attn_implementation=\"flash_attention_2\",\n",
    "            low_cpu_mem_usage=True\n",
    "        )\n",
    "\n",
    "        # Enable memory efficient features\n",
    "        self.model.gradient_checkpointing_enable()\n",
    "        self.model.enable_input_require_grads()\n",
    "\n",
    "        #self.model = torch.compile(self.model)\n",
    "\n",
    "        # device_map = infer_auto_device_map(model, max_memory={0: \"14GiB\", \"cpu\": \"64GiB\"})\n",
    "\n",
    "        # model = AutoModelForCausalLM.from_pretrained(\n",
    "        #     model_name,\n",
    "        #     trust_remote_code=True,\n",
    "        #     #device_map=\"auto\",  # Let Accelerate handle device placement\n",
    "        #     device_map=device_map,  # Let Accelerate handle device placement\n",
    "        #     quantization_config=bnb_config,\n",
    "        #     torch_dtype=torch.bfloat16,\n",
    "        #     config=autoconfig,\n",
    "        #     attn_implementation=\"flash_attention_2\"\n",
    "        # )\n",
    "\n",
    "        # peft_config = LoraConfig(\n",
    "        #     r=8,\n",
    "        #     lora_alpha=16,\n",
    "        #     lora_dropout=0.1,\n",
    "        #     target_modules=[\"q_proj\", \"v_proj\"],\n",
    "        #     bias=\"none\",\n",
    "        #     task_type=\"CAUSAL_LM\"\n",
    "        # )\n",
    "        \n",
    "        \n",
    "        # self.model = get_peft_model(model, peft_config)#.to('cpu')\n",
    "        # self.model.gradient_checkpointing_enable()\n",
    "\n",
    "        # self.relic_node_positions = []\n",
    "        # self.discovered_relic_nodes_ids = set()\n",
    "        # self.unit_explore_locations = dict()\n",
    "\n",
    "    def prep_llm_input(self, env_cfg, obs):\n",
    "\n",
    "        game_state_info = \"\\n!!!GAME STATE INFORMATION!!!\"\n",
    "\n",
    "        ### env_cfg information\n",
    "        env_cfg_info = \"\\nENVIRONMENT CONFIGURATION:\"\n",
    "        max_units = f\"\\nMaximum possible number of units for each team: {env_cfg['max_units']}.\"\n",
    "        match_count_per_episode = f\"\\nNumber of matches per game: {env_cfg['match_count_per_episode']}.\"\n",
    "        max_steps_in_match = f\"\\nNumber of steps per match: {env_cfg['max_steps_in_match']}.\"\n",
    "        map_height = f\"\\nMap height: {env_cfg['map_height']}.\"\n",
    "        map_width = f\"\\nMap width: {env_cfg['map_width']}.\"\n",
    "        num_teams = f\"\\nNumber of teams: {env_cfg['num_teams']}.\"\n",
    "        unit_move_cost = f\"\\nUnit move energy cost: {env_cfg['unit_move_cost']}.\"\n",
    "        unit_sap_cost = f\"\\nUnit sap energy cost: {env_cfg['unit_sap_cost']}.\"\n",
    "        unit_sap_range = f\"\\nUnit sap range: {env_cfg['unit_sap_range']}.\"\n",
    "        unit_sensor_range = f\"\\nUnit sensor range: {env_cfg['unit_sensor_range']}.\"\n",
    "\n",
    "        ### obs information\n",
    "        obs_info = \"\\nOBSERVATION:\"\n",
    "        unit_position_warning = \"\\nUnit position: -1, -1 means the unit is not spawned yet or not visible.\"\n",
    "\n",
    "        # unit positions\n",
    "        unit_position_info = \"\\nUnit Positions:\"\n",
    "        obs_my_unit_positions = obs['units']['position'][self.team_id]\n",
    "        my_unit_positions_list = []\n",
    "        for i in range(obs_my_unit_positions.shape[0]):\n",
    "            pos = obs_my_unit_positions[i]\n",
    "            my_unit_positions_list.append(f\"\\nMy unit {i} position: {pos[0]}, {pos[1]}.\")\n",
    "        my_unit_positions = \"\".join(my_unit_positions_list)\n",
    "\n",
    "        obs_enemy_unit_positions = obs['units']['position'][self.enemy_team_id]\n",
    "        enemy_unit_positions_list = []\n",
    "        for i in range(obs_enemy_unit_positions.shape[0]):\n",
    "            pos = obs_enemy_unit_positions[i]\n",
    "            enemy_unit_positions_list.append(f\"\\nEnemy unit {i} position: {pos[0]}, {pos[1]}.\")\n",
    "        enemy_unit_positions = \"\".join(enemy_unit_positions_list)\n",
    "\n",
    "        # unit energys\n",
    "        unit_energy_info = \"\\nUnit Energys:\"\n",
    "        obs_my_unit_energys = obs['units']['energy'][self.team_id]\n",
    "        my_unit_energys_list = []\n",
    "        for i in range(obs_my_unit_energys.shape[0]):\n",
    "            energy = obs_my_unit_energys[i]\n",
    "            my_unit_energys_list.append(f\"\\nMy unit {i} energy: {energy}.\")\n",
    "        my_unit_energys = \"\".join(my_unit_energys_list)\n",
    "\n",
    "        obs_enemy_unit_energys = obs['units']['energy'][self.enemy_team_id]\n",
    "        enemy_unit_energys_list = []\n",
    "        for i in range(obs_enemy_unit_energys.shape[0]):\n",
    "            energy = obs_enemy_unit_energys[i]\n",
    "            enemy_unit_energys_list.append(f\"\\nEnemy unit {i} energy: {energy}.\")\n",
    "        enemy_unit_energys = \"\".join(enemy_unit_energys_list)\n",
    "\n",
    "        # unit masks\n",
    "        unit_mask_info = \"\\nUnit Visibility:\"\n",
    "        obs_my_units_mask = obs['units_mask'][self.team_id]\n",
    "        my_units_mask_list = []\n",
    "        for i in range(obs_my_units_mask.shape[0]):\n",
    "            mask = obs_my_units_mask[i]\n",
    "            my_units_mask_list.append(f\"\\nMy unit {i} visibility: {mask}.\")\n",
    "        my_units_mask = \"\".join(my_units_mask_list)\n",
    "\n",
    "        obs_enemy_units_mask = obs['units_mask'][self.enemy_team_id]\n",
    "        enemy_units_mask_list = []\n",
    "        for i in range(obs_enemy_units_mask.shape[0]):\n",
    "            mask = obs_enemy_units_mask[i]\n",
    "            enemy_units_mask_list.append(f\"\\nEnemy unit {i} visibility: {mask}.\")\n",
    "        enemy_units_mask = \"\".join(enemy_units_mask_list)\n",
    "\n",
    "        # sensor mask\n",
    "        sensor_mask_info = \"\\nSensor Mask:\"\n",
    "        obs_sensor_mask = obs['sensor_mask']\n",
    "        sensor_mask_list = []\n",
    "        for i in range(obs_sensor_mask.shape[0]):\n",
    "            sensor_mask_list.append(f\"\\nSensor mask row {i}: {str(obs_sensor_mask[i]).replace(\"[\", \"\").replace(\"]\", \"\")}.\")\n",
    "        sensor_mask = \"\".join(sensor_mask_list)\n",
    "\n",
    "        # map features - energy\n",
    "        map_features_energy_info = \"\\nMap Energys:\"\n",
    "        obs_map_features_energy = obs['map_features']['energy']\n",
    "        map_features_energy_list = []\n",
    "        for i in range(obs_map_features_energy.shape[0]):\n",
    "            map_features_energy_list.append(f\"\\nMap energy row {i}: {str(obs_map_features_energy[i]).replace(\"[\", \"\").replace(\"]\", \"\")}.\")\n",
    "        map_features_energy = \"\".join(map_features_energy_list)\n",
    "\n",
    "        # map features - tile_type\n",
    "        map_features_tile_type_info = \"\\nMap Tile Types:\"\n",
    "        obs_map_features_tile_type = obs['map_features']['tile_type']\n",
    "        map_features_tile_type_list = []\n",
    "        for i in range(obs_map_features_tile_type.shape[0]):\n",
    "            map_features_tile_type_list.append(f\"\\nMap tile type row {i}: {str(obs_map_features_tile_type[i]).replace(\"[\", \"\").replace(\"]\", \"\")}.\")\n",
    "        map_features_tile_type = \"\".join(map_features_tile_type_list)\n",
    "\n",
    "        # relic nodes\n",
    "        relic_node_info = \"\\nRelic Node positions:\"\n",
    "        relic_node_warning = \"\\nRelic node position: -1, -1 means the relic node is not yet discoverd.\"\n",
    "        obs_relic_nodes = obs['relic_nodes']\n",
    "        relic_nodes_list = []\n",
    "        for i in range(obs_relic_nodes.shape[0]):\n",
    "            relic_nodes_list.append(f\"\\nRelic node {i} position: {obs_relic_nodes[i][0]}, {obs_relic_nodes[i][1]}.\")\n",
    "        relic_nodes = \"\".join(relic_nodes_list)\n",
    "\n",
    "        # relic nodes mask\n",
    "        relic_node_mask_info = \"\\nRelic Node Visibility:\"\n",
    "        obs_relic_nodes_mask = obs['relic_nodes_mask']\n",
    "        relic_nodes_mask_list = []\n",
    "        for i in range(obs_relic_nodes_mask.shape[0]):\n",
    "            relic_nodes_mask_list.append(f\"\\nRelic node {i} visibility: {obs_relic_nodes_mask[i]}.\")\n",
    "        relic_nodes_mask = \"\".join(relic_nodes_mask_list)\n",
    "\n",
    "        # team points\n",
    "        my_team_points = f\"\\nMy current point for this match is: {obs['team_points'][self.team_id]}.\"\n",
    "        enemy_team_points = f\"\\nEnemy current point for this match is: {obs['team_points'][self.enemy_team_id]}.\"\n",
    "\n",
    "        # team wins\n",
    "        my_team_wins = f\"\\nI have won {obs['team_wins'][self.team_id]} matches.\"\n",
    "        enemy_team_wins = f\"\\nEnemy has won {obs['team_wins'][self.enemy_team_id]} matches.\"\n",
    "\n",
    "        # steps\n",
    "        steps = f\"\\nThis is step {obs['steps']} of the game.\"\n",
    "\n",
    "        # match_steps\n",
    "        match_steps = f\"\\nThis is step {obs['match_steps']} of the match.\"\n",
    "\n",
    "        if self.enemy_spawn_location is None:\n",
    "            enemy_spawn_location_warning = \"\\nEnemy spawn location: not yet discovered.\"\n",
    "        else:\n",
    "            enemy_spawn_location_warning = f\"\\nEnemy spawn location: {self.enemy_spawn_location[0]}, {self.enemy_spawn_location[1]}.\"\n",
    "        \n",
    "        all_variables = \"\".join([\n",
    "            game_state_info, env_cfg_info, max_units, match_count_per_episode, max_steps_in_match, map_height, map_width, num_teams, unit_move_cost, unit_sap_cost, unit_sap_range, unit_sensor_range,\n",
    "            obs_info,\n",
    "            unit_position_warning, unit_position_info, my_unit_positions, enemy_unit_positions,\n",
    "            unit_energy_info, my_unit_energys, enemy_unit_energys,\n",
    "            unit_mask_info, my_units_mask, enemy_units_mask,\n",
    "            sensor_mask_info, sensor_mask,\n",
    "            map_features_energy_info, map_features_energy,\n",
    "            map_features_tile_type_info, map_features_tile_type,\n",
    "            relic_node_info, relic_node_warning, relic_nodes,\n",
    "            relic_node_mask_info, relic_nodes_mask,\n",
    "            my_team_points, enemy_team_points, my_team_wins, enemy_team_wins, steps, match_steps, enemy_spawn_location_warning\n",
    "        ])\n",
    "\n",
    "        return {'content':all_variables, 'role':'user'}\n",
    "\n",
    "    def act(self, step: int, obs, remainingOverageTime: int = 60):\n",
    "        \"\"\"implement this function to decide what actions to send to each available unit. \n",
    "        \n",
    "        step is the current timestep number of the game starting from 0 going up to max_steps_in_match * match_count_per_episode - 1.\n",
    "        \"\"\"\n",
    "\n",
    "        # units\n",
    "        unit_positions = np.array(obs[\"units\"][\"position\"][self.team_id]) # shape (max_units, 2)\n",
    "        # enemy_unit_positions = np.array(obs[\"units\"][\"position\"][self.enemy_team_id]) # shape (max_units, 2)\n",
    "\n",
    "        # unit_energys = np.array(obs[\"units\"][\"energy\"][self.team_id]) # shape (max_units, 1)\n",
    "        # enemy_unit_energys = np.array(obs[\"units\"][\"energy\"][self.enemy_team_id]) # shape (max_units, 1)\n",
    "\n",
    "        # units_mask\n",
    "        unit_mask = np.array(obs[\"units_mask\"][self.team_id]) # shape (max_units, )\n",
    "        # enemy_unit_mask = np.array(obs[\"units_mask\"][self.enemy_team_id]) # shape (max_units, )\n",
    "\n",
    "        # sensor_mask\n",
    "        # sensor_mask = obs['sensor_mask']\n",
    "\n",
    "        # map_features\n",
    "        map_features = obs['map_features']\n",
    "        # current_map_energy = map_features['energy']\n",
    "        current_map_tile_type = map_features['tile_type']\n",
    "\n",
    "        # update map explored status\n",
    "        self.map_explored_status[current_map_tile_type != -1] = 1\n",
    "        \n",
    "        # observed_relic_node_positions = np.array(obs[\"relic_nodes\"]) # shape (max_relic_nodes, 2)\n",
    "        # observed_relic_nodes_mask = np.array(obs[\"relic_nodes_mask\"]) # shape (max_relic_nodes, )\n",
    "        # team_points = np.array(obs[\"team_points\"]) # points of each team, team_points[self.team_id] is the points of the your team\n",
    "        \n",
    "        # ids of units you can control at this timestep\n",
    "        available_unit_ids = np.where(unit_mask)[0]\n",
    "        # enemy_available_unit_ids = np.where(enemy_unit_mask)[0]\n",
    "\n",
    "        if available_unit_ids.shape[0] == 0:\n",
    "            pass\n",
    "        else:\n",
    "            if self.first_spawn == False:\n",
    "                first_unit_id = available_unit_ids[0]\n",
    "                first_unit_pos = unit_positions[first_unit_id]\n",
    "                self.my_spawn_location = (first_unit_pos[0], first_unit_pos[1])\n",
    "                self.enemy_spawn_location = find_opposite_corner_coords(self.map_explored_status, first_unit_pos[0], first_unit_pos[1])\n",
    "                self.first_spawn = True\n",
    "        \n",
    "        # visible relic nodes\n",
    "        # visible_relic_node_ids = set(np.where(observed_relic_nodes_mask)[0])\n",
    "\n",
    "        self.llm_input = self.prep_llm_input(self.env_cfg, obs)\n",
    "\n",
    "        actions = np.zeros((self.env_cfg[\"max_units\"], 3), dtype=int)\n",
    "                \n",
    "        return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b1d6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = RecordEpisode(\n",
    "    LuxAIS3GymEnv(numpy_output=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d718d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_all, info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85f0d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent0 = Agent(\"player_0\", info['params'])\n",
    "#agent1 = Agent(\"player_1\", info['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994e4c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions0 = agent0.act(obs_all['player_0']['steps'], obs_all['player_0'])\n",
    "#actions1 = agent1.act(obs_all['player_1']['steps'], obs_all['player_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fba4992",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_input = game_rules['content'] + agent0.llm_input['content']\n",
    "temp_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3242aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_tokens = tokenizer(temp_input, return_tensors=\"pt\", max_length=10000, truncation=False, padding=\"max_length\")\n",
    "temp_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd77645",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_tokens['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd75b498",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_tokens['attention_mask'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409be0a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ec19b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e4dbce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7474961",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dataset = Dataset.from_list([{'prompt': [answer_format, game_rules, agent0.llm_input]}])\n",
    "temp_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b740f695",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57917ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648edf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_fn(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"question\"],  # Ensure these keys exist in your dataset\n",
    "        #examples[\"answer\"],\n",
    "        padding=\"max_length\",  # Ensure uniform length\n",
    "        truncation=True,  # Prevent excessive token length issues\n",
    "        max_length=512,  # Adjust based on your model's requirements\n",
    "        return_tensors=\"pt\"\n",
    "    )#.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230368a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = train_data.map(tokenize_fn, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc57632d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = tokenized_dataset.remove_columns(['question', 'answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ba42c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cb33f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0d0bcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6876db3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e2ca89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ed4b86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d6b8be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb642226",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent0.llm_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43239786",
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_score = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0dc307",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_score = obs_all['player_0']['team_points'][0]\n",
    "current_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c71758",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_score = current_score - previous_score\n",
    "reward_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad949a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reward functions\n",
    "def strict_format_reward_func(completions, **kwargs) -> list[float]:\n",
    "    \"\"\"Reward function that checks if the completion has a specific format.\"\"\"\n",
    "    pattern = r\"^<reasoning>\\n.*?\\n</reasoning>\\n<answer>\\n.*?\\n</answer>\\n$\"\n",
    "    responses = [completion[0][\"content\"] for completion in completions]\n",
    "    matches = [re.match(pattern, r) for r in responses]\n",
    "\n",
    "    return [0.5 if match else 0.0 for match in matches]\n",
    "\n",
    "def soft_format_reward_func(completions, **kwargs) -> list[float]:\n",
    "    \"\"\"Reward function that checks if the completion has a specific format.\"\"\"\n",
    "    pattern = r\"<reasoning>.*?</reasoning>\\s*<answer>.*?</answer>\"\n",
    "    responses = [completion[0][\"content\"] for completion in completions]\n",
    "    matches = [re.match(pattern, r) for r in responses]\n",
    "\n",
    "    return [0.5 if match else 0.0 for match in matches]\n",
    "\n",
    "def count_xml(text) -> float:\n",
    "    count = 0.0\n",
    "    if text.count(\"<reasoning>\\n\") == 1:\n",
    "        count += 0.125\n",
    "        count -= len(text.split(\"<reasoning>\\n\")[0])*0.001\n",
    "    if text.count(\"\\n</reasoning>\\n\") == 1:\n",
    "        count += 0.125\n",
    "    if text.count(\"\\n<answer>\\n\") == 1:\n",
    "        count += 0.125\n",
    "        count -= len(text.split(\"\\n</answer>\\n\")[-1])*0.001\n",
    "    if text.count(\"\\n</answer>\") == 1:\n",
    "        count += 0.125\n",
    "        count -= (len(text.split(\"\\n</answer>\")[-1]) - 1)*0.001\n",
    "\n",
    "    return count\n",
    "\n",
    "def xmlcount_reward_func(completions, **kwargs) -> list[float]:\n",
    "    contents = [completion[0][\"content\"] for completion in completions]\n",
    "\n",
    "    return [count_xml(c) for c in contents]\n",
    "\n",
    "def answer_format_reward_func(completions, **kwargs) -> list[float]:\n",
    "    responses = [completion[0][\"content\"] for completion in completions]\n",
    "    answers = [extract_xml_answer(r) for r in responses]\n",
    "    answer_pattern = re.compile(r\"^Unit \\d+: (0|1|2|3|4|5(, -?\\d+, -?\\d+)?) # (move up|move right|move down|move left|center|sap at \\(-?\\d+, -?\\d+\\) relative to unit \\d+'s current position)$\")\n",
    "\n",
    "    scores = []\n",
    "    for answer in answers:\n",
    "        answer_score = 0.0\n",
    "        for action in answer.split(\"\\n\"):\n",
    "            if answer_pattern.match(action):\n",
    "                answer_score += 0.5 / 16\n",
    "                unit_number = int(action.split(\":\")[0].split(\" \")[1])\n",
    "                if unit_number < 0 or unit_number > 15:\n",
    "                    answer_score -= 0.1 / 16\n",
    "            if len(action) != 16:\n",
    "                answer_score -= 0.1\n",
    "        scores.append(answer_score)\n",
    "\n",
    "    return scores\n",
    "\n",
    "def point_gain_reward_func(completions, **kwargs) -> list[float]:\n",
    "\n",
    "    return [reward_score for completion in completions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18b8bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb1011b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27b664b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir=\"outputs/DeepSeek-R1-Distill-Qwen-1.5B-PPO\"\n",
    "run_name=\"DeepSeek-R1-Distill-Qwen-1.5B-PPO-20250211_02\"\n",
    "\n",
    "training_args = PPOConfig(\n",
    "    output_dir=output_dir,\n",
    "    run_name=run_name,\n",
    "    batch_size=1,\n",
    "    learning_rate=5e-6,\n",
    "    adam_beta1=0.9,\n",
    "    adam_beta2=0.99,\n",
    "    weight_decay=0.1,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    logging_steps=1,\n",
    "    bf16=True,\n",
    "    gradient_accumulation_steps=1,\n",
    "    num_sample_generations=0,\n",
    "    max_grad_norm=0.1,\n",
    "    num_train_epochs=1,\n",
    "    save_steps=1,\n",
    "    log_on_each_node=False,\n",
    "    report_to=\"none\",\n",
    "    num_ppo_epochs=1,\n",
    "    cliprange=0.2,\n",
    "    vf_coef=1.0,\n",
    "    kl_coef=0.01,\n",
    "    prediction_loss_only=True,\n",
    "    gradient_checkpointing=True,\n",
    "    #reward_model_path=\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\n",
    "    optim=\"adamw_torch_fused\",\n",
    "    #use_cpu=True,\n",
    "    max_steps=1,\n",
    "    #eval_steps=1,\n",
    "    #eval_accumulation_steps=8,\n",
    "    #accelerator_config={\"num_processes\": 8},\n",
    "    per_device_train_batch_size=1,\n",
    "    #per_device_eval_batch_size=1,\n",
    "    torch_empty_cache_steps=1,\n",
    "    #torch_compile=True,\n",
    "    #torch_compile_mode=\"default\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a8e369",
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_input = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41da6f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_fn(something):\n",
    "    #print(something)\n",
    "    global unknown_input\n",
    "    #unknown_input = copy.deepcopy(something)  # Save for debugging\n",
    "    unknown_input = something  # Save for debugging\n",
    "\n",
    "    #print(\"Original shape:\", something.shape)  # Debugging\n",
    "\n",
    "    # Reduce hidden dimensions → shape: (batch_size, 1)\n",
    "    something = something.mean(dim=2)#.unsqueeze(-1)\n",
    "\n",
    "    #print(\"Reduced shape:\", something.shape)  # Debugging\n",
    "\n",
    "    if torch.isnan(something).any() or torch.isinf(something).any():\n",
    "        raise ValueError(\"score_fn produced NaN or Inf values!\")\n",
    "    \n",
    "    #return torch.zeros(something.shape[0]).to('cuda', dtype=torch.bfloat16)\n",
    "\n",
    "    return something#.to('cuda', dtype=torch.bfloat16)  # Ensure it's on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a84eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent0.model.score = score_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87839c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Modified_PPO_Trainer.ppo_trainer64 import PPOTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688d06ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = PPOTrainer(\n",
    "    model=agent0.model,\n",
    "    value_model=agent0.model,\n",
    "    processing_class=tokenizer,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    ref_model=None,\n",
    "    reward_model=agent0.model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f3a42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.args.output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ec3625",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598e7d84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bf0db3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d41a47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f1f296",
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe71fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bac1416",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_test = unknown_input.mean(dim=2)\n",
    "test_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cd5031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718375fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d745008",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "reward_model_name = \"gpt2\"\n",
    "reward_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    reward_model_name,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    use_cache=False,\n",
    "    low_cpu_mem_usage=True,\n",
    ")\n",
    "#reward_tokenizer = AutoTokenizer.from_pretrained(reward_model_name)\n",
    "reward_model.gradient_checkpointing_enable()\n",
    "reward_model.enable_input_require_grads()\n",
    "\n",
    "#reward_model = torch.compile(reward_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b68202a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2caffa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea85bc35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48563b81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93a8233",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1e6aa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db29ea65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reward_model.score = score_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e2f674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78eb5dba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 10395677,
     "sourceId": 86411,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 143.048125,
   "end_time": "2024-12-26T20:02:43.573801",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-26T20:00:20.525676",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
